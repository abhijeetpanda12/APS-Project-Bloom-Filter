{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import mmh3\n",
    "from bitarray import bitarray\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use murmur3 for generating hash functions and bitarray for storing the bloom filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this application we have a dataset of 20,000 malicious URLs for creating our bloom filter\n",
    "\n",
    "As checking  each URL that user entered on browser against the malicious URL  database can make the browser slow.\n",
    "\n",
    "Therefore any URL was first checked against a local Bloom filter, and only if the Bloom filter returned a positive result was a full check of the URL performed (and the user warned, if that too returned a positive result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = 100000\n",
    "# bit_array = bitarray(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Positive in bloom filter depends size of bitarray and number of hash functions used.\n",
    "For optimal results we will set no of elements to be inserted to 20000 and false positive rate to 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20000\n",
    "p = 0.05\n",
    "m = -(n * math.log(p))/(math.log(2)**2)\n",
    "k = (m/n) * math.log(2) \n",
    "size = int(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m denote size of bloom filter\n",
    "k denote no of hash functions used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124704"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.321928094887363"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_array = bitarray(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using bitarray(size), we will initialize the bit_array with given size and set all enteries to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for build --- 0.07630491256713867 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bit_array.setall(0)\n",
    "\n",
    "def mapf(url):\n",
    "    b1 = mmh3.hash(url, 1) % size\n",
    "    bit_array[b1]=1\n",
    "\n",
    "    b2 = mmh3.hash(url, 2) % size\n",
    "    bit_array[b2]=1\n",
    "\n",
    "    b3 = mmh3.hash(url, 3) % size\n",
    "    bit_array[b3]=1\n",
    "\n",
    "    b4 = mmh3.hash(url, 4) % size\n",
    "    bit_array[b4]=1\n",
    "\n",
    "#     b5 = mmh3.hash(url, 5) % size\n",
    "#     bit_array[b5]=1\n",
    "\n",
    "#     b6 = mmh3.hash(url, 6) % size\n",
    "#     bit_array[b6]=1\n",
    "\n",
    "#     b7 = mmh3.hash(url, 7) % size\n",
    "#     bit_array[b7]=1\n",
    "\n",
    "\n",
    "r = csv.reader(open(\"new_data.csv\"))\n",
    "for row in r:\n",
    "    url=row[1]\n",
    "    mapf(url)\n",
    "print(\"Time for build --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapf() function is used to set the bloom filter indexes for each url passed as parameter.Each URL is passed to hash functions and indexes return by the hash functions are set to 1 in bloom filter bit array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n",
      "Time for check --- 0.004625082015991211 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "disk_accesses=0;\n",
    "\n",
    "ba = bit_array\n",
    "\n",
    "def check(url):\n",
    "    global disk_accesses\n",
    "    b1 = mmh3.hash(url, 1) % size\n",
    "    b2 = mmh3.hash(url, 2) % size\n",
    "    b3 = mmh3.hash(url, 3) % size\n",
    "    b4 = mmh3.hash(url, 4) % size\n",
    "#     b5 = mmh3.hash(url, 5) % size\n",
    "#     b6 = mmh3.hash(url, 6) % size\n",
    "#     b7 = mmh3.hash(url, 7) % size\n",
    "    if(ba[b1]==True \n",
    "    and ba[b2]==True \n",
    "    and ba[b3]==True \n",
    "    and ba[b4]==True \n",
    "#     and ba[b5]==True \n",
    "#     and ba[b6]==True \n",
    "#     and ba[b7]==True\n",
    "      ):\n",
    "        disk_accesses=disk_accesses+1\n",
    "\n",
    "\n",
    "\n",
    "r = csv.reader(open(\"top2m.csv\"))\n",
    "\n",
    "for row in r:\n",
    "    url=row[1]\n",
    "    check(url)\n",
    "print(disk_accesses);\n",
    "\n",
    "print(\"Time for check --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check(url) function will be used to test whether URL is present in file or not using bloom filter.\n",
    "top2m.csv contains URLs which are not present in our initial malicious url file.\n",
    "We will count the false positives.\n",
    "To analyze our result, we have vary the number of hash functions and size of bloom filter and get the false positive values and using this dataset of different numbers of hash function, varied size of bloom filter and false positive values we will plot the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Time for check --- 0.2752988338470459 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "link = csv.reader(open(\"new_data.csv\"))\n",
    "data=[]\n",
    "for item in link:\n",
    "    data.append(item[1])\n",
    "test = csv.reader(open(\"top2m.csv\"))\n",
    "count=0\n",
    "for number,item in test:\n",
    "    if item in data:\n",
    "        count+=1\n",
    "print(count)\n",
    "print(\"Time for check --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are checking the actual time taken if for every URL that needs to be checked we are going through the file to check if url is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
